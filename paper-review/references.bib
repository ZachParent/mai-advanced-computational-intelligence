@article{Zheng2023PPO,
  title={{Secrets of RLHF in Large Language Models Part I: PPO}},
  author={Zheng, Rui and Dou, Shihan and Gao, Songyang and Jin, Senjie and Liu, Qin and Xu, Nuo and Lai, Wenbin and Hua, Yuan and Shen, Wei and Wang, Binghai and Liu, Yan and Zhou, Yuhao and Xiong, Limao and Chen, Lu and Xi, Zhiheng and Zhu, Minghao and Chang, Cheng and Yin, Zhangyue and Weng, Rongxiang and Cheng, Wensen and Huang, Haoran and Sun, Tianxiang and Yan, Hang and Gui, Tao and Zhang, Qi and Qiu, Xipeng and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2307.04964},
  year={2023},
  archivePrefix={arXiv},
  eprint={2307.04964}
}

@article{Dai2023SafeRLHF,
  title={{Safe RLHF: Safe Reinforcement Learning from Human Feedback}},
  author={Dai, Josef and Pan, Xuehai and Sun, Ruiyang and Ji, Jiaming and Xu, Xinbo and Liu, Mickel and Wang, Yizhou and Yang, Yaodong},
  journal={arXiv preprint arXiv:2310.12773},
  year={2023},
  archivePrefix={arXiv},
  eprint={2310.12773}
}

@article{Ouyang2022InstructGPT,
  title={{Training language models to follow instructions with human feedback}},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Christiano, Paul and Welinder, Peter},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022},
  archivePrefix={arXiv},
  eprint={2203.02155}
}

@article{Casper2023OpenProblems,
  title={{Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback}},
  author={Casper, Stephen and Davies, Xander and Shi, Claudia and Krendl Gilbert, Thomas and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and Wang, Tony Tong and Marks, Samuel and Segerie, Charbel-Rapha{\"e}l and Carroll, Micah and Peng, Andi and Christoffersen, Phillip and Raje, Saurav and Prakash, Mayank and Razin, Elessar and Sigal, Rebecca and Zorowitz, Nora and Hobbhahn, Maximilian and Human, Anonymous and Krasheninnikov, Daniel and Grimsley, Amanda and Ackley, David and Kuelbs, Eileen and Chan, Peter and Ghosh, Shreshth and Kaddour, Jean and Heiner, Moritz and Krueger, David},
  journal={Transactions on Machine Learning Research},
  year={2023},
  eprint={2307.15217},
  archivePrefix={arXiv}
}

@article{Fu2024RewardShaping,
  title={{Reward Shaping to Mitigate Reward Hacking in RLHF}},
  author={Fu, Jiayi and Zhao, Xuandong and Yao, Chengyuan and Wang, Heng and Han, Qi and Xiao, Yanghua},
  journal={arXiv preprint arXiv:2402.18770},
  year={2024},
  archivePrefix={arXiv},
  eprint={2402.18770}
}

@article{Zhang2024EnergyLoss,
  title={{The Energy Loss Phenomenon in RLHF: A New Perspective on Mitigating Reward Hacking}},
  author={Zhang, Han and Liu, Ruixuan and Miao, Ruosen and Zhang, Zhaofei and Zhang, Weinan and Yu, Yong and Wang, Shuai},
  journal={arXiv preprint arXiv:2401.12358},
  year={2024},
  archivePrefix={arXiv},
  eprint={2401.12358}
}

@article{Lian2024AligningToWhat,
   title={{Aligning to What? On the (In)Effectiveness of RLHF in Mitigating Covert Biases}},
   author={Lian, Eric and Budhathoki, Sauhard and Head, Andrew and Sasha, Dennis},
   journal={arXiv preprint arXiv:2403.09025},
   year={2024},
   archivePrefix={arXiv},
   eprint={2403.09025}
}
